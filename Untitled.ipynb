{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandpit\n",
    "\n",
    "Goal: figure out how to use model to predict a region's pop density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from geopandas import GeoDataFrame, GeoSeries, read_file\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, shape\n",
    "from shapely.prepared import prep\n",
    "import shapely.ops as ops\n",
    "from pandas import Series, DataFrame\n",
    "from descartes import PolygonPatch\n",
    "import fiona\n",
    "import rasterio\n",
    "from osgeo import gdal, ogr\n",
    "from rtree import index\n",
    "import shapefile\n",
    "from itertools import *\n",
    "from functools import partial\n",
    "import pyproj\n",
    "import pickle, cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_county = GeoDataFrame.from_file('county_2010_census/County_2010Census_DP1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 3)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the CNN model estimates\n",
    "df_prediction = pickle.load(file('prediction_db.p', 'rb'))\n",
    "df_prediction.columns = df_prediction.iloc[0]\n",
    "df_prediction = df_prediction.reindex(df_prediction.index.drop(0))\n",
    "df_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spatial index\n",
    "county_blocks = np.array(db_county['geometry'])\n",
    "idx = index.Index()\n",
    "count = 0\n",
    "for c_block in county_blocks:\n",
    "    idx.insert(count, c_block.bounds)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign each point to a county\n",
    "pixels_location = np.array(df_prediction[['lon', 'lat']])\n",
    "pixel_county = []\n",
    "count = 0\n",
    "for location in pixels_location:\n",
    "    pixel = Point(location)\n",
    "    temp_polygon = None\n",
    "    for j in idx.intersection((pixel.x, pixel.y)):\n",
    "        if pixel.within(county_blocks[j]):\n",
    "            temp_polygon = county_blocks[j]\n",
    "            break\n",
    "    pixel_county.append([temp_polygon, location[0], location[1]])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "interpolated_pop = cPickle.load(file('mapping/y_interpolated.save', 'rb'))\n",
    "interpolated_loc = cPickle.load(file('mapping/location.save', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "db = GeoDataFrame(interpolated_loc)\n",
    "db['pop'] = interpolated_pop\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# combine datasets. check that locations match in each row\n",
    "pixel_county = np.array(pixel_county)\n",
    "df_prediction['latitude'] = pixel_county[:,2]\n",
    "df_prediction['longitude'] = pixel_county[:,1]\n",
    "df_prediction['geometry'] = pixel_county[:,0] \n",
    "print (df_prediction['lat']==df_prediction['latitude']).sum() == df_prediction.shape[0]\n",
    "print (df_prediction['lon']==df_prediction['longitude']).sum() == df_prediction.shape[0]\n",
    "# delete unnecessary columns\n",
    "df_prediction = df_prediction.drop(['lat', 'lon'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collecting centroids for merge\n",
    "def getXY(pt):\n",
    "    return (pt.x, pt.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# centroids for county data\n",
    "centroidseries = db_county['geometry'].centroid\n",
    "x,y = [list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "db_county['centroid_latitude'] = x\n",
    "db_county['centroid_longitude'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropping empty geometries (e.g. oceans) and getting centroids\n",
    "df_prediction = df_prediction.dropna(subset=['geometry'], how='all')\n",
    "centroidseries = [df_prediction.iloc[i]['geometry'].centroid for i in range(\n",
    "                    len(df_prediction))]\n",
    "x,y = [list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "df_prediction['centroid_latitude'] = x\n",
    "df_prediction['centroid_longitude'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.merge(df_prediction, db_county, on=['centroid_latitude', 'centroid_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = ['estimate', 'geometry_y','geometry_x', 'NAMELSAD10', 'DP0010001']\n",
    "result = result[variables]\n",
    "# check that merge was ok\n",
    "(result['geometry_y'] == result['geometry_x']).sum() == result.shape[0]\n",
    "# cleaning df\n",
    "result.drop(['geometry_y'], axis=1)\n",
    "result.rename(columns={'geometry_x' : 'geometry'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting area in sqkm\n",
    "area_sq_degrees = result['geometry']\n",
    "area_sq_km = []\n",
    "\n",
    "for region in area_sq_degrees:\n",
    "    geom_area = ops.transform(\n",
    "        partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(init='EPSG:4326'),\n",
    "        pyproj.Proj(\n",
    "            proj='aea',\n",
    "            lat1=region.bounds[1],\n",
    "            lat2=region.bounds[3])),\n",
    "        region)\n",
    "    area = geom_area.area / 1e6 # convert to km2\n",
    "    area_sq_km.append( area )\n",
    "\n",
    "result['area'] = area_sq_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result['census_density'] = result['DP0010001'] / result['area'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result['census_density'] = result['census_density'].astype(float)\n",
    "result['estimate'] = result['estimate'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimate_density = DataFrame(result.groupby(['NAMELSAD10'])['estimate'].mean())\n",
    "actual_density = DataFrame(result.groupby(['NAMELSAD10'])['census_density'].mean())\n",
    "output = pd.merge( estimate_density, actual_density, left_index=True, right_index=True)\n",
    "output.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "engine = create_engine('mysql+pymysql://root:@localhost/website_db', echo=False)\n",
    "output.to_sql('website_database', engine, chunksize=20000)\n",
    "output.to_csv('website_database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
